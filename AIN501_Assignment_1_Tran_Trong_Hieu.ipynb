{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34IrLag9smNg"
      },
      "source": [
        "# AIN501 - Deep learning\n",
        "## Assignment 1 - CIFAR 10\n",
        "### Tran Trong Hieu - MSE23185"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7XfIp7l4L8u"
      },
      "source": [
        "#### I. Import and check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USRaL7x322R9",
        "outputId": "29765ea7-2004-4644-caf8-5548855f4a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Import section\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import os\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeWmi-WZ4Wq7"
      },
      "source": [
        "#### II. Load dataset CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jObev6so4cnq"
      },
      "outputs": [],
      "source": [
        "# Transform\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Batch size\n",
        "batch_size_train = 64\n",
        "batch_size_test = 100\n",
        "\n",
        "# Load dataset CIFAR-10\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size_train, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=batch_size_test, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define 10 classes of CIFAR-10 dataset\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP6eSPB-6gmS"
      },
      "source": [
        "#### III. Build model with informations:\n",
        "1. Using CNN with ELU activation function\n",
        "2. Loss fuction: Cross entropy loss\n",
        "3. Optimizer: Adam\n",
        "4. Early stop and check point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "py4uK_nP7ebU"
      },
      "outputs": [],
      "source": [
        "# CNN model with ELU activation fuction\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, 3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ELU(),\n",
        "      nn.Conv2d(64, 64, 3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ELU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Dropout(0.3)\n",
        "    )\n",
        "\n",
        "    self.conv2 = nn.Sequential(\n",
        "      nn.Conv2d(64, 128, 3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ELU(),\n",
        "      nn.Conv2d(128, 128, 3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ELU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Dropout(0.4)\n",
        "    )\n",
        "\n",
        "    self.conv3 = nn.Sequential(\n",
        "      nn.Conv2d(128, 256, 3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ELU(),\n",
        "      nn.Conv2d(256, 256, 3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ELU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Dropout(0.5)\n",
        "    )\n",
        "\n",
        "    self.conv4 = nn.Sequential(\n",
        "      nn.Conv2d(256, 512, 3, padding=1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ELU(),\n",
        "      nn.Conv2d(512, 512, 3, padding=1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ELU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Dropout(0.5)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(512 * 2 * 2, 512),\n",
        "      nn.ELU(),\n",
        "      nn.Dropout(0.5),\n",
        "      nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c0q_Vs-O2dq"
      },
      "source": [
        "#### IV. Define optimizer, loss function and early stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L1QPMfB3POnx"
      },
      "outputs": [],
      "source": [
        "# Define optimizer, loss function and early stop\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "best_loss = float('inf')\n",
        "early_stop_count = 0\n",
        "patience = 7\n",
        "save_path = 'cnn_model.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL0ThUHMQ0-x"
      },
      "source": [
        "#### V. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EqbgLNeQ3_v",
        "outputId": "e127af3e-5158-4ada-a69a-4802d8ab6548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Loss: 0.9148\n",
            "Saved Best Model\n",
            "Epoch [2/200], Loss: 0.9070\n",
            "Saved Best Model\n",
            "Epoch [3/200], Loss: 0.9066\n",
            "Saved Best Model\n",
            "Epoch [4/200], Loss: 0.9023\n",
            "Saved Best Model\n",
            "Epoch [5/200], Loss: 0.8971\n",
            "Saved Best Model\n",
            "Epoch [6/200], Loss: 0.8983\n",
            "Epoch [7/200], Loss: 0.8913\n",
            "Saved Best Model\n",
            "Epoch [8/200], Loss: 0.8841\n",
            "Saved Best Model\n",
            "Epoch [9/200], Loss: 0.8840\n",
            "Saved Best Model\n",
            "Epoch [10/200], Loss: 0.8823\n",
            "Saved Best Model\n",
            "Epoch [11/200], Loss: 0.8788\n",
            "Saved Best Model\n",
            "Epoch [12/200], Loss: 0.8728\n",
            "Saved Best Model\n",
            "Epoch [13/200], Loss: 0.8728\n",
            "Epoch [14/200], Loss: 0.8658\n",
            "Saved Best Model\n",
            "Epoch [15/200], Loss: 0.8689\n",
            "Epoch [16/200], Loss: 0.8636\n",
            "Saved Best Model\n",
            "Epoch [17/200], Loss: 0.8618\n",
            "Saved Best Model\n",
            "Epoch [18/200], Loss: 0.8586\n",
            "Saved Best Model\n",
            "Epoch [19/200], Loss: 0.8547\n",
            "Saved Best Model\n",
            "Epoch [20/200], Loss: 0.8566\n",
            "Epoch [21/200], Loss: 0.8537\n",
            "Saved Best Model\n",
            "Epoch [22/200], Loss: 0.8486\n",
            "Saved Best Model\n",
            "Epoch [23/200], Loss: 0.8473\n",
            "Saved Best Model\n",
            "Epoch [24/200], Loss: 0.8430\n",
            "Saved Best Model\n",
            "Epoch [25/200], Loss: 0.8436\n",
            "Epoch [26/200], Loss: 0.8401\n",
            "Saved Best Model\n",
            "Epoch [27/200], Loss: 0.8397\n",
            "Saved Best Model\n",
            "Epoch [28/200], Loss: 0.8374\n",
            "Saved Best Model\n",
            "Epoch [29/200], Loss: 0.8321\n",
            "Saved Best Model\n",
            "Epoch [30/200], Loss: 0.8320\n",
            "Saved Best Model\n",
            "Epoch [31/200], Loss: 0.8324\n",
            "Epoch [32/200], Loss: 0.8287\n",
            "Saved Best Model\n",
            "Epoch [33/200], Loss: 0.8280\n",
            "Saved Best Model\n",
            "Epoch [34/200], Loss: 0.8286\n",
            "Epoch [35/200], Loss: 0.8264\n",
            "Saved Best Model\n",
            "Epoch [36/200], Loss: 0.8278\n",
            "Epoch [37/200], Loss: 0.8240\n",
            "Saved Best Model\n",
            "Epoch [38/200], Loss: 0.8246\n",
            "Epoch [39/200], Loss: 0.8232\n",
            "Saved Best Model\n",
            "Epoch [40/200], Loss: 0.8196\n",
            "Saved Best Model\n",
            "Epoch [41/200], Loss: 0.8191\n",
            "Saved Best Model\n",
            "Epoch [42/200], Loss: 0.8173\n",
            "Saved Best Model\n",
            "Epoch [43/200], Loss: 0.8191\n",
            "Epoch [44/200], Loss: 0.8146\n",
            "Saved Best Model\n",
            "Epoch [45/200], Loss: 0.8163\n",
            "Epoch [46/200], Loss: 0.8129\n",
            "Saved Best Model\n",
            "Epoch [47/200], Loss: 0.8115\n",
            "Saved Best Model\n",
            "Epoch [48/200], Loss: 0.8102\n",
            "Saved Best Model\n",
            "Epoch [49/200], Loss: 0.8101\n",
            "Saved Best Model\n",
            "Epoch [50/200], Loss: 0.8100\n",
            "Saved Best Model\n",
            "Epoch [51/200], Loss: 0.8022\n",
            "Saved Best Model\n",
            "Epoch [52/200], Loss: 0.8040\n",
            "Epoch [53/200], Loss: 0.8044\n",
            "Epoch [54/200], Loss: 0.8022\n",
            "Epoch [55/200], Loss: 0.8041\n",
            "Epoch [56/200], Loss: 0.7696\n",
            "Saved Best Model\n",
            "Epoch [57/200], Loss: 0.7620\n",
            "Saved Best Model\n",
            "Epoch [58/200], Loss: 0.7565\n",
            "Saved Best Model\n",
            "Epoch [59/200], Loss: 0.7551\n",
            "Saved Best Model\n",
            "Epoch [60/200], Loss: 0.7511\n",
            "Saved Best Model\n",
            "Epoch [61/200], Loss: 0.7507\n",
            "Saved Best Model\n",
            "Epoch [62/200], Loss: 0.7462\n",
            "Saved Best Model\n",
            "Epoch [63/200], Loss: 0.7490\n",
            "Epoch [64/200], Loss: 0.7485\n",
            "Epoch [65/200], Loss: 0.7439\n",
            "Saved Best Model\n",
            "Epoch [66/200], Loss: 0.7441\n",
            "Epoch [67/200], Loss: 0.7436\n",
            "Saved Best Model\n",
            "Epoch [68/200], Loss: 0.7425\n",
            "Saved Best Model\n",
            "Epoch [69/200], Loss: 0.7399\n",
            "Saved Best Model\n",
            "Epoch [70/200], Loss: 0.7395\n",
            "Saved Best Model\n",
            "Epoch [71/200], Loss: 0.7379\n",
            "Saved Best Model\n",
            "Epoch [72/200], Loss: 0.7372\n",
            "Saved Best Model\n",
            "Epoch [73/200], Loss: 0.7378\n",
            "Epoch [74/200], Loss: 0.7380\n",
            "Epoch [75/200], Loss: 0.7343\n",
            "Saved Best Model\n",
            "Epoch [76/200], Loss: 0.7373\n",
            "Epoch [77/200], Loss: 0.7380\n",
            "Epoch [78/200], Loss: 0.7356\n",
            "Epoch [79/200], Loss: 0.7328\n",
            "Saved Best Model\n",
            "Epoch [80/200], Loss: 0.7317\n",
            "Saved Best Model\n",
            "Epoch [81/200], Loss: 0.7339\n",
            "Epoch [82/200], Loss: 0.7332\n",
            "Epoch [83/200], Loss: 0.7338\n",
            "Epoch [84/200], Loss: 0.7298\n",
            "Saved Best Model\n",
            "Epoch [85/200], Loss: 0.7350\n",
            "Epoch [86/200], Loss: 0.7296\n",
            "Saved Best Model\n",
            "Epoch [87/200], Loss: 0.7311\n",
            "Epoch [88/200], Loss: 0.7300\n",
            "Epoch [89/200], Loss: 0.7296\n",
            "Saved Best Model\n",
            "Epoch [90/200], Loss: 0.7278\n",
            "Saved Best Model\n",
            "Epoch [91/200], Loss: 0.7290\n",
            "Epoch [92/200], Loss: 0.7288\n",
            "Epoch [93/200], Loss: 0.7279\n",
            "Epoch [94/200], Loss: 0.7262\n",
            "Saved Best Model\n",
            "Epoch [95/200], Loss: 0.7279\n",
            "Epoch [96/200], Loss: 0.7252\n",
            "Saved Best Model\n",
            "Epoch [97/200], Loss: 0.7257\n",
            "Epoch [98/200], Loss: 0.7279\n",
            "Epoch [99/200], Loss: 0.7252\n",
            "Epoch [100/200], Loss: 0.7281\n",
            "Epoch [101/200], Loss: 0.7223\n",
            "Saved Best Model\n",
            "Epoch [102/200], Loss: 0.7227\n",
            "Epoch [103/200], Loss: 0.7243\n",
            "Epoch [104/200], Loss: 0.7223\n",
            "Epoch [105/200], Loss: 0.7211\n",
            "Saved Best Model\n",
            "Epoch [106/200], Loss: 0.7212\n",
            "Epoch [107/200], Loss: 0.7212\n",
            "Epoch [108/200], Loss: 0.7215\n",
            "Epoch [109/200], Loss: 0.7182\n",
            "Saved Best Model\n",
            "Epoch [110/200], Loss: 0.7212\n",
            "Epoch [111/200], Loss: 0.7186\n",
            "Epoch [112/200], Loss: 0.7197\n",
            "Epoch [113/200], Loss: 0.7193\n",
            "Epoch [114/200], Loss: 0.7183\n",
            "Epoch [115/200], Loss: 0.7200\n",
            "Epoch [116/200], Loss: 0.7181\n",
            "Saved Best Model\n",
            "Epoch [117/200], Loss: 0.7214\n",
            "Epoch [118/200], Loss: 0.7203\n",
            "Epoch [119/200], Loss: 0.7209\n",
            "Epoch [120/200], Loss: 0.7198\n",
            "Epoch [121/200], Loss: 0.7208\n",
            "Epoch [122/200], Loss: 0.7197\n",
            "Epoch [123/200], Loss: 0.7194\n",
            "Early stopping triggered\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}\")\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "    # Early stopping logic\n",
        "    if epoch_loss < best_loss:\n",
        "      best_loss = epoch_loss\n",
        "      early_stop_count = 0\n",
        "      torch.save(model.state_dict(), save_path)\n",
        "      print(\"Saved Best Model\")\n",
        "    else:\n",
        "      early_stop_count += 1\n",
        "      if early_stop_count >= patience:\n",
        "          print(\"Early stopping triggered\")\n",
        "          break\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csvg8OzdRumh"
      },
      "source": [
        "#### VI. Evaluation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o8QreNzRyes",
        "outputId": "44658f58-8218-4280-ab68-7a9f6c31a791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Loss: 0.688480\n",
            "\n",
            "Test Accuracy of plane     : 91% (914/1000)\n",
            "Test Accuracy of car       : 96% (959/1000)\n",
            "Test Accuracy of bird      : 88% (877/1000)\n",
            "Test Accuracy of cat       : 78% (780/1000)\n",
            "Test Accuracy of deer      : 95% (950/1000)\n",
            "Test Accuracy of dog       : 87% (866/1000)\n",
            "Test Accuracy of frog      : 96% (960/1000)\n",
            "Test Accuracy of horse     : 95% (946/1000)\n",
            "Test Accuracy of ship      : 96% (964/1000)\n",
            "Test Accuracy of truck     : 96% (956/1000)\n",
            "Test Accuracy (Overall): 92% (9172/10000)\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "def evaluate(model, testloader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    class_correct = [0] * 10\n",
        "    class_total = [0] * 10\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                pred = predicted[i]\n",
        "                if label == pred:\n",
        "                    class_correct[label] += 1\n",
        "                class_total[label] += 1\n",
        "\n",
        "    print(f\"\\nTest Loss: {total_loss / total:.6f}\\n\")\n",
        "    for i in range(10):\n",
        "        acc = 100 * class_correct[i] / class_total[i]\n",
        "        print(f\"Test Accuracy of {classes[i]:10}: {acc:.0f}% ({class_correct[i]}/{class_total[i]})\")\n",
        "    print(f\"Test Accuracy (Overall): {100 * correct / total:.0f}% ({correct}/{total})\")\n",
        "\n",
        "evaluate(model, testloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
